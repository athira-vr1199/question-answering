{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_QA.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADSDszNudr3i"
      },
      "source": [
        "!mkdir squad\n",
        "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n",
        "# !wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhhCEmDqd9LL"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    print(squad_dict)\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "\n",
        "train_contexts, train_questions, train_answers = read_squad('/content/drive/MyDrive/BERT/data/train_UK_2word_same_frst_word_30k_with_extra_symbols.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('/content/drive/MyDrive/BERT/data/val_UK_2word_same_frst_word_30k_with_extra_symbols.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7wmfWQxeIAq"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # sometimes squad answers are off by a character or two â€“ fix this\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfTBpFENeXjb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8WHB9gMIirM"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWS9uomWeUdj"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "# from transformers import AutoTokenizer\n",
        "    \n",
        "# tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeRy3zOlcVXA"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV0A4sz8ef0O"
      },
      "source": [
        "\n",
        "\n",
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3eYJ8M0dSB3"
      },
      "source": [
        "for x in train_encodings[\"input_ids\"][:5]:\n",
        "    print(tokenizer.decode(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF_UkMjVejt_"
      },
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHMjputwhurG"
      },
      "source": [
        "val_dataset[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzX170XwewTS"
      },
      "source": [
        "from transformers import DistilBertForQuestionAnswering\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMauMb660vZm"
      },
      "source": [
        "# path_to_model =\"model/pytorch_model.bin\"\n",
        "# # print(\".............\",path)\n",
        "# config = DistilBertConfig.from_pretrained(path + \"/config.json\")\n",
        "# # tokenizer = DistilBertTokenizer.from_pretrained(path, do_lower_case=self.do_lower_case)\n",
        "# model = DistilBertForQuestionAnswering.from_pretrained(path_to_model, from_tf=False, config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jpUrwpffECN"
      },
      "source": [
        "\n",
        "batch_size=8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce9yT07Ie-67"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"/content/drive/MyDrive/BERT/test-squad3\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    save_steps=100000,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=12,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm1AORJEfMw4"
      },
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "data_collator = default_data_collator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XthuXctafWbF"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6yCc4cUfqut"
      },
      "source": [
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyZ0QW-sgB5-"
      },
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/BERT/model_UK_2word_first_word_same_50k_random_with_symbol_batch8_epoch20\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjhBqDZWFutY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YNbCxpDiG4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ8fU18SHMfk"
      },
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjSzxxPMF9lg"
      },
      "source": [
        "# context = \"The US has passed the peak on new coronavirus cases, \" \\\n",
        "#           \"President Donald Trump said and predicted that some states would reopen this month. \" \\\n",
        "#           \"The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\"\n",
        "\n",
        "# question = \"What was President Donald Trump's prediction?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6zpyzUqF5EH"
      },
      "source": [
        "trainer.predict(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYL4HuLDm-J"
      },
      "source": [
        "import torch\n",
        "\n",
        "for batch in trainer.get_eval_dataloader():\n",
        "    break\n",
        "batch = {k: v.to(trainer.args.device) for k, v in batch.items()}\n",
        "with torch.no_grad():\n",
        "    output = trainer.model(**batch)\n",
        "output.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bQDbnVDpF8"
      },
      "source": [
        "output.start_logits.shape, output.end_logits.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCJFDLFoDtH8"
      },
      "source": [
        "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgU4MF7XEaUh"
      },
      "source": [
        "n_best_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED8hRUypEimo"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "start_logits = output.start_logits[0].cpu().numpy()\n",
        "end_logits = output.end_logits[0].cpu().numpy()\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n",
        "                }\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6YsKyjRGezy"
      },
      "source": [
        "validation_features = val_dataset.map(\n",
        "    prepare_validation_features,\n",
        "    batched=True,\n",
        "    remove_columns=val_dataset.column_names\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-2AhPbEp0E"
      },
      "source": [
        "raw_predictions = trainer.predict(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZXy5jaoHqzr"
      },
      "source": [
        "val_contexts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eIeX2gpF8Jy"
      },
      "source": [
        "# start_logits = output.start_logits[0].cpu().numpy()\n",
        "# end_logits = output.end_logits[0].cpu().numpy()\n",
        "# # offset_mapping = val_dataset[0][\"offset_mapping\"]\n",
        "# # The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
        "# # an example index\n",
        "# context = val_contexts\n",
        "\n",
        "# # Gather the indices the best start/end logits:\n",
        "# start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "# end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "# valid_answers = []\n",
        "# for start_index in start_indexes:\n",
        "#     for end_index in end_indexes:\n",
        "#         # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "#         # to part of the input_ids that are not in the context.\n",
        "#         # if (\n",
        "#         #     start_index >= len(offset_mapping)\n",
        "#         #     or end_index >= len(offset_mapping)\n",
        "#         #     or offset_mapping[start_index] is None\n",
        "#         #     or offset_mapping[end_index] is None\n",
        "#         # ):\n",
        "#         #     continue\n",
        "#         # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "#         if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "#             continue\n",
        "#         if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "#             start_char = offset_mapping[start_index][0]\n",
        "#             end_char = offset_mapping[end_index][1]\n",
        "#             valid_answers.append(\n",
        "#                 {\n",
        "#                     \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "#                     \"text\": context[start_char: end_char]\n",
        "#                 }\n",
        "#             )\n",
        "\n",
        "# valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "# valid_answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSDHbc8e1ZW"
      },
      "source": [
        "21# from torch.utils.data import DataLoader\n",
        "# from transformers import AdamW\n",
        "\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# model.to(device)\n",
        "# model.train()\n",
        "\n",
        "# train_loader = DataLoader(train_dataset,batch_size=2, shuffle=True)\n",
        "# print(train_loader)\n",
        "# optim = AdamW(model.parameters(), lr=5e-5)\n",
        "# print(\"len:\",len(train_loader))\n",
        "# for epoch in range(1,2):\n",
        "#     print(\"epoch:\",epoch)\n",
        "#     i=0\n",
        "#     for batch in train_loader:\n",
        "\n",
        "#         # print(i)\n",
        "#         # i+=1\n",
        "#         optim.zero_grad()\n",
        "#         input_ids = batch['input_ids'].to(device)\n",
        "#         attention_mask = batch['attention_mask'].to(device)\n",
        "#         start_positions = batch['start_positions'].to(device)\n",
        "#         end_positions = batch['end_positions'].to(device)\n",
        "#         outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "#         loss = outputs[0]\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "\n",
        "# model.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLZD_mslGAsL"
      },
      "source": [
        "model.save_pretrained(\"squad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQk2-bFzBnvN"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yGuh1mECwU"
      },
      "source": [
        "from transformers import BertConfig, BertModel,TFBertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOsBvb1BCuHY"
      },
      "source": [
        "config = BertConfig.from_json_file('./squad/config.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM3VuQG9CKrV"
      },
      "source": [
        "model = TFBertModel.from_pretrained('./squad/pytorch_model.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxhSwSDqgm4J"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-DDHRGxgomA"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}